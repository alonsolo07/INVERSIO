"""
scoring_etfs.py
----------------------------------
Pipeline principal para el c√°lculo de scoring, ranking y predicci√≥n de ETFs.

Version: 1.7.0 - Implementaci√≥n de Pesos Din√°micos por Grupo de Riesgo.
    - El peso de las m√©tricas de Riesgo/Volatilidad (KID_SRI, Sharpe, Alfa)
      y Rendimiento (PREDICTED_COL) se ajusta seg√∫n el 'Grupo' del ETF.
    - Se garantiza la equidad en el scoring entre clases de activos.

Autor: EVOLVE Research (TFM Project)
An√°lisis y Mejora: Tu Tutor de ML/DS
"""

import pandas as pd
import numpy as np
import logging

# ======================================================
# üß≠ CONFIGURACI√ìN DE LOGGING PROFESIONAL
# ======================================================
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s",
    handlers=[logging.StreamHandler()]
)
logger = logging.getLogger(__name__)

# Columna utilizada para la predicci√≥n de rendimiento anualizada
PREDICTED_COL = "Rentabilidad_Anual_Predicha"

# ======================================================
# ‚öñÔ∏è CONFIGURACI√ìN GLOBAL BASE DE M√âTRICAS
# ======================================================
# Esta es la base, que ser√° SOBREESCRITA por los pesos din√°micos en la funci√≥n de scoring.
METRICS_CONFIG_BASE = {
    # Factores de Calidad/Rendimiento Ajustado (su peso var√≠a fuertemente)
    "Alfa_3A√±os_Mensual": {"direction": "higher"},
    "Sharpe_3A√±os_Mensual": {"direction": "higher"},
    PREDICTED_COL: {"direction": "higher"},
    "KID_SRI": {"direction": "lower"},
    
    # Factores Secundarios/Constantes (mantienen un peso fijo en todos los grupos)
    "Costes": {"weight": 0.75, "direction": "lower"}, # Expense Ratio
    "Rent_1A√±o%": {"weight": 0.3, "direction": "higher"},
    "Patrimonio": {"weight": 0.25, "direction": "higher"},
}

# ======================================================
# üéØ CONFIGURACI√ìN DE PESOS DIN√ÅMICOS POR GRUPO (N√öCLEO DEL CAMBIO)
# ======================================================
DYNAMIC_WEIGHTS = {
    # GRUPO 1: BAJO RIESGO (Cash, RF Corto Plazo) - PRIORIDAD: Seguridad
    1: {
        "KID_SRI": 1.5,                 # Peso M√°ximo para la seguridad
        "Sharpe_3A√±os_Mensual": 1.25,
        "Alfa_3A√±os_Mensual": 0.75,
        PREDICTED_COL: 0.5,             # Bajo peso al retorno, no es el objetivo
    },
    
    # GRUPO 2: MEDIO RIESGO (Renta Variable Core, Sectorial) - PRIORIDAD: Rendimiento Ajustado
    2: {
        "KID_SRI": 0.5,                 # Bajo peso: No penalizar la volatilidad natural de la RV
        "Sharpe_3A√±os_Mensual": 1.5,    # Peso M√°ximo: Medida clave en RV
        "Alfa_3A√±os_Mensual": 1.0,
        PREDICTED_COL: 1.0,             # Importante
    },
    
    # GRUPO 3: ALTO RIESGO/ESPECIALES (Emergentes, Materias Primas) - PRIORIDAD: Comp. por Riesgo
    3: {
        "KID_SRI": 0.75,                # Peso intermedio: Penalizar riesgo excesivo, pero permitirlo
        "Sharpe_3A√±os_Mensual": 1.0,
        "Alfa_3A√±os_Mensual": 1.25,     # Premiar fuertemente el Alpha (outperformance)
        PREDICTED_COL: 1.25,            # Premiar fuertemente el retorno esperado (compensaci√≥n)
    },
}

# ======================================================
# ‚öôÔ∏è CARGA Y LIMPIEZA DE DATOS
# ======================================================
def cargar_datos(path_csv: str) -> pd.DataFrame:
    """Carga los datos, limpia NaNs b√°sicos y convierte columnas a tipos num√©ricos."""
    logger.info("üîç Preparando datos de entrada...")
    try:
        df = pd.read_csv(path_csv)
    except FileNotFoundError:
        logger.error(f"Error fatal: No se encontr√≥ el archivo en {path_csv}")
        return pd.DataFrame()
        
    base_cols = ["Categor√≠a", "Grupo", "Precio", "Costes", "Patrimonio"]
    
    # Obtener todas las claves de METRICS_CONFIG_BASE y DYNAMIC_WEIGHTS para asegurar columnas
    required_metrics = set(METRICS_CONFIG_BASE.keys())
    for weights in DYNAMIC_WEIGHTS.values():
        required_metrics.update(weights.keys())
        
    required_cols = set(list(required_metrics) + base_cols + ["Rent_3A√±os%", "Rent_5A√±os%", "Rent_10A√±os%"])
    for col in required_cols:
        if col not in df.columns:
            df[col] = np.nan
            
    df = df.dropna(subset=base_cols)
    
    numeric_cols = [col for col in df.columns if 'Rent_' in col or col in ['Precio', 'Patrimonio', 'Costes', 'KID_SRI', 'Sharpe_3A√±os_Mensual', 'Alfa_3A√±os_Mensual']]
    
    for col in numeric_cols:
        if col in df.columns:
            df[col] = pd.to_numeric(df[col], errors='coerce')
            
    logger.info(f"‚úÖ ETFs v√°lidos tras limpieza inicial: {len(df)}")
    return df

# ======================================================
# üí° FUNCI√ìN: EXTRAPOLACI√ìN PONDERADA
# ======================================================
def extrapolar_rentabilidad_anual(df: pd.DataFrame) -> pd.DataFrame:
    """
    Calcula la Rentabilidad Anual Predicha (PREDICTED_COL) mediante una media ponderada
    de todos los retornos hist√≥ricos disponibles.
    """
    df = df.copy()
    logger.info("üí° Calculando Rentabilidad Anual Predicha (Extrapolaci√≥n Ponderada)...")
    
    # Definici√≥n de las m√©tricas de rendimiento y sus pesos/factores de anualizaci√≥n
    RENT_CONFIG = {
        "Rent_1Mes%":   {"factor": 12.0, "weight": 0.2},
        "Rent_3Meses%": {"factor": 4.0,  "weight": 0.3},
        "Rent_6Meses%": {"factor": 2.0,  "weight": 0.5},
        "Rent_1A√±o%":   {"factor": 1.0,  "weight": 1.0},
        "Rent_3A√±os%":  {"factor": 1/3,  "weight": 1.0},
        "Rent_5A√±os%":  {"factor": 1/5,  "weight": 1.0},
        "Rent_10A√±os%": {"factor": 1/10, "weight": 1.0},
    }
    
    df[PREDICTED_COL] = np.nan
    
    total_weighted_return = pd.Series(0.0, index=df.index)
    total_applicable_weight = pd.Series(0.0, index=df.index)
    
    for col, config in RENT_CONFIG.items():
        if col in df.columns:
            annualized_return = df[col] * config['factor']
            weight = config['weight']
            
            has_data_mask = annualized_return.notna()
            
            total_weighted_return[has_data_mask] += annualized_return[has_data_mask] * weight
            total_applicable_weight[has_data_mask] += weight
            
    final_annual_prediction = total_weighted_return.divide(total_applicable_weight)
    
    df[PREDICTED_COL] = final_annual_prediction.where(total_applicable_weight > 0)
    
    predicted_count = df[PREDICTED_COL].notna().sum()
    logger.info(f"‚úÖ Rentabilidad Anual Predicha calculada para {predicted_count} ETFs.")
    
    return df

# ======================================================
# üßÆ C√ÅLCULO DE SCORE COMPUESTO Y RANKING (PESOS DIN√ÅMICOS)
# ======================================================
def _calculate_score_by_group(df: pd.DataFrame, grouping_col: str, weights_by_group: dict) -> pd.DataFrame:
    """
    Calcula un score normalizado y ponderado (0-10) por grupo,
    utilizando pesos espec√≠ficos definidos en weights_by_group.
    """
    score_col_name = f"Score_{grouping_col}"
    rank_col_name = f"Rank_{grouping_col}"
    df[score_col_name] = np.nan

    logger.info(f"‚öñÔ∏è Calculando scores din√°micos para '{grouping_col}' con pesos espec√≠ficos...")

    for group_id, group_df in df.groupby(grouping_col):
        # 1. Obtener la configuraci√≥n de pesos espec√≠fica para este grupo
        group_weights = weights_by_group.get(group_id, {})
        
        # Combinar con la configuraci√≥n base para tener todas las m√©tricas
        final_config = METRICS_CONFIG_BASE.copy()
        
        # Aplicar el peso din√°mico sobre la base (o usar el peso base si no es din√°mico)
        for metric, base_conf in METRICS_CONFIG_BASE.items():
            final_config[metric]['weight'] = group_weights.get(metric, base_conf.get('weight', 1.0)) # 1.0 por defecto
            
        group_indices = group_df.index
        total_weighted_score = pd.Series(0.0, index=group_indices)
        total_applicable_weight = pd.Series(0.0, index=group_indices)
        
        for metric, config in final_config.items():
            # Obtener el peso espec√≠fico para el grupo
            weight = config['weight']
            direction = config['direction']
            
            group_metric_data = group_df[metric]
            
            if group_metric_data.isna().all():
                continue

            # 1. Normalizaci√≥n (Min-Max Scaling) dentro del grupo
            min_v, max_v = group_metric_data.min(), group_metric_data.max()
            
            if min_v == max_v:
                norm_score = pd.Series(0.5, index=group_indices)
            else:
                norm_score = (group_metric_data - min_v) / (max_v - min_v)
            
            # 2. Direcci√≥n
            if direction == 'lower':
                norm_score = 1 - norm_score
            
            # Ponderaci√≥n y Acumulaci√≥n Neutral (solo si el ETF tiene el dato)
            has_data_mask = norm_score.notna()
            
            total_weighted_score[has_data_mask] += norm_score[has_data_mask] * weight
            total_applicable_weight[has_data_mask] += weight
            
        # 4. C√ÅLCULO DEL SCORE FINAL POR ETF
        final_score = total_weighted_score.divide(total_applicable_weight).fillna(np.nan)

        df.loc[group_indices, score_col_name] = final_score

    # 5. Escalado final (0-10) sobre TODOS los scores calculados
    valid_scores = df[score_col_name].dropna()
    if not valid_scores.empty:
        min_score, max_score = valid_scores.min(), valid_scores.max()
        if min_score != max_score:
            df[score_col_name] = (df[score_col_name] - min_score) / (max_score - min_score) * 10
        else:
            df[score_col_name] = 5.0 
    
    df[score_col_name] = df[score_col_name].round(2)
    
    # 6. Ranking
    df[rank_col_name] = df.groupby(grouping_col)[score_col_name].rank(
        ascending=False, method="dense", na_option='bottom'
    ).fillna(0).astype(int)
    
    return df


def calcular_score(df: pd.DataFrame) -> pd.DataFrame:
    """Controlador principal para el c√°lculo de scores por Categor√≠a y Grupo (con pesos din√°micos)."""
    df_scored = df.copy()
    
    if "Grupo" not in df_scored.columns:
        logger.warning("Columna 'Grupo' no encontrada. Se usar√° 'Categor√≠a' como 'Grupo'.")
        df_scored["Grupo"] = df_scored["Categor√≠a"]
        
    # Usamos la l√≥gica de pesos din√°micos por Grupo para el ranking de Grupo
    df_scored = _calculate_score_by_group(df_scored, "Grupo", DYNAMIC_WEIGHTS)
    
    # Para el ranking de Categor√≠a, si no tienes una l√≥gica espec√≠fica, podemos usar un peso promedio o el peso del Grupo 2 (RV Core)
    # Por simplicidad y robustez, usaremos la l√≥gica del Grupo 2 como fallback para la Categor√≠a.
    logger.warning("Usando pesos del GRUPO 2 para el ranking a nivel de 'Categor√≠a'.")
    df_scored = _calculate_score_by_group(df_scored, "Categor√≠a", {cat: DYNAMIC_WEIGHTS.get(2, {}) for cat in df_scored['Categor√≠a'].unique()})
    
    logger.info("‚úÖ Scores y rankings calculados con pesos din√°micos.")
    return df_scored

# ======================================================
# üíæ EXPORTACI√ìN DE RESULTADOS (Mantenida de v1.6.5)
# ======================================================
def exportar_resultados(df: pd.DataFrame, n_top: int = 5):
    """
    Exporta el registro maestro completo y los rankings Top N.
    """
    logger.info(f"üíæ Exportando resultados completos y Top {n_top}...")

    required_cols = ["Rank_Categoria", "Rank_Grupo", "Score_Categoria", "Score_Grupo", PREDICTED_COL]
    for col in required_cols:
        if col not in df.columns:
            logger.warning(f"La columna '{col}' no existe. Rellenando con 0.0 para exportaci√≥n.")
            df[col] = 0.0
    
    cols_topn_grupo = ["Nombre", "ISIN", "Grupo", "Rank_Grupo", PREDICTED_COL]

    # 3. Guardar CSV completo (REGISTRO MAESTRO)
    output_file_all = "etfs_scored.csv"
    df_sorted = df.loc[:,~df.columns.duplicated()].copy() 
    df_sorted = df_sorted.sort_values(by=["Categor√≠a", "Rank_Categoria"], ascending=True)
    df_sorted.to_csv(output_file_all, index=False, encoding='utf-8')
    logger.info(f"‚úÖ Archivo completo exportado: {output_file_all}")
    
    # 4. Top N por categor√≠a (Salida completa)
    top_categoria = df[df["Rank_Categoria"] <= n_top].sort_values(
        by=["Categor√≠a", "Rank_Categoria"]
    )
    top_categoria.to_csv("topN_categoria.csv", index=False, encoding='utf-8')

    # 5. Top N por grupo (SALIDA MINIMALISTA SOLICITADA)
    top_grupo_full = df[df["Rank_Grupo"] <= n_top].sort_values(
        by=["Grupo", "Rank_Grupo"]
    )
    # Filtrar solo por las columnas solicitadas
    top_grupo_minimal = top_grupo_full[cols_topn_grupo] 
    
    top_grupo_minimal.to_csv("topN_grupo.csv", index=False, encoding='utf-8')

    logger.info(f"‚úÖ Archivos Top {n_top} exportados (Top por Grupo en formato minimalista).")


# ======================================================
# üöÄ MAIN PIPELINE
# ======================================================
def main():
    """Ejecuta el pipeline completo: Carga -> Extrapolaci√≥n -> Scoring -> Exportaci√≥n."""
    logger.info("üöÄ Iniciando pipeline de scoring y ranking ETFs")
    
    df = cargar_datos("../limpios/etfs.csv") 
    
    if df.empty:
        logger.error("No se cargaron datos. Abortando pipeline.")
        return
        
    df = extrapolar_rentabilidad_anual(df) 
    
    df = calcular_score(df)
    
    exportar_resultados(df)
    
    logger.info("üéâ Pipeline finalizado con √©xito.")

if __name__ == "__main__":
    main()